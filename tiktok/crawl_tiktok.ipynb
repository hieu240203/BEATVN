{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from My_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_path = \"dict_data.json\"\n",
    "output_file = \"data_video.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Link_kenh = pd.read_excel(\"Link_kenh_lau.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver = setup_driver()\n",
    "\n",
    "# # Đọc danh sách liên kết từ file TXT\n",
    "\n",
    "# data_page = []\n",
    "# dict_Data = {}\n",
    "\n",
    "# # Mở từng liên kết và cuộn trang\n",
    "# for i in range (0,len(Link_kenh)):\n",
    "#     try:\n",
    "#         driver.get(Link_kenh['Link'][i])\n",
    "#         time.sleep(random.randint(10, 15))  # Chờ một khoảng thời gian ngẫu nhiên\n",
    "#         scroll_until_end(driver, duration=5)  # Hàm cuộn trang tới cuối\n",
    "        \n",
    "#         # Lấy mã nguồn của trang sau khi cuộn xong\n",
    "#         page_source = driver.page_source\n",
    "        \n",
    "#         # Sử dụng BeautifulSoup để phân tích cú pháp HTML\n",
    "#         soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        \n",
    "#         class_video = extract_first_class(soup)\n",
    "\n",
    "#         # Tìm tất cả các phần tử cần thiết\n",
    "#         elements = soup.find_all('div', class_=class_video)\n",
    "#         video_links = extract_links(elements)  # Lấy liên kết video\n",
    "#         views_video = extract_view_video(elements)  # Lấy lượt xem video\n",
    "#         ghim = extract_ghim(elements)  # Lấy dữ liệu ghim\n",
    "\n",
    "#         # Thêm dữ liệu vào dict_Data\n",
    "#         dict_Data[Link_kenh[\"Link\"][i]] = {\n",
    "#             'video_link': video_links,\n",
    "#             'view': views_video,\n",
    "#             'ghim': ghim\n",
    "#         }\n",
    "        \n",
    "#         # Thu thập thông tin từ trang cá nhân\n",
    "#         data_page_1 = extract_user_info(soup, Link_kenh['Link'][i], Link_kenh['Hệ Network'][i])\n",
    "#         data_page.append(data_page_1)  # Lưu thông tin người dùng vào danh sách\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Đã xảy ra lỗi khi mở liên kết {Link_kenh['Link'][i]}: {e}\")\n",
    "\n",
    "# # Ghi dữ liệu người dùng vào file sau khi thu thập đủ dữ liệu\n",
    "# with open('user_data.txt', 'a', encoding='utf-8') as f:  # Sử dụng 'a' để thêm dữ liệu mà không ghi đè\n",
    "#     for user_data in data_page:\n",
    "#         data_page_content = '\\n'.join(f\"{key}: {value}\" for key, value in user_data.items())\n",
    "#         f.write(data_page_content + \"\\n\")\n",
    "\n",
    "# # Lưu `dict_Data` vào một file nếu cần thiết (ví dụ dưới dạng JSON)\n",
    "# with open('dict_data.json', 'w', encoding='utf-8') as f:    \n",
    "#     json.dump(dict_Data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.strptime(\"7-1-2024\", '%m-%d-%Y')\n",
    "end_time = datetime.strptime(\"10-27-2024\", '%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # driver = setup_driver()\n",
    "# await main_async(dict_data_path, output_file, start_time, end_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = setup_driver()\n",
    "\n",
    "dict_Data = {}\n",
    "try:\n",
    "    with open('dict_data.json', 'r', encoding='utf-8') as f:\n",
    "        dict_Data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(\"File dict_data.json chưa tồn tại, tạo mới dict_Data.\")\n",
    "\n",
    "# Danh sách để lưu trữ dữ liệu từ các bài đăng\n",
    "data_posts = []\n",
    "\n",
    "with open('data_video.txt', 'a', encoding='utf-8') as file:\n",
    "    for key, value in dict_Data.items():  # Duyệt qua cả key và value trong dict_Data\n",
    "        video_links = value['video_link']  # Lấy danh sách video links\n",
    "        views = value['view']  # Lấy danh sách views\n",
    "        ghim = value['ghim']\n",
    "        for link, view, is_ghim in zip(video_links, views, ghim):\n",
    "            view_video = chuan_hoa_luot_thich(view)\n",
    "\n",
    "            try:  # <======\n",
    "                driver.get(link)\n",
    "                WebDriverWait(driver, 10).until(  # <======\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, 'body'))  # <======\n",
    "                )\n",
    "                data_post = collect_data_from_link(driver, link, view_video, is_ghim)\n",
    "            except Exception as e:  # <======\n",
    "                print(f\"Lỗi khi mở link {link}: {e}\")  # <======\n",
    "                continue  # <======\n",
    "\n",
    "            post_date = data_post[\"Ngày đăng\"]  # Giả sử `post_date` là kiểu datetime\n",
    "            \n",
    "            # Kiểm tra điều kiện về ngày đăng và ghim\n",
    "            if post_date is None or not isinstance(post_date, datetime):\n",
    "                continue\n",
    "\n",
    "            if (post_date < start_time) and not is_ghim:\n",
    "                break\n",
    "\n",
    "            if is_ghim and (post_date < start_time or post_date > end_time):\n",
    "                continue\n",
    "\n",
    "            if post_date < start_time or post_date > end_time:\n",
    "                continue\n",
    "\n",
    "            if data_post:\n",
    "                # Chuyển đổi các đối tượng datetime trong data_post sang chuỗi\n",
    "                data_post_serializable = convert_datetime_to_str(data_post)\n",
    "\n",
    "                # Ghi dữ liệu dưới dạng JSON vào file\n",
    "                data_posts.append(data_post_serializable)\n",
    "                file.write(json.dumps(data_post_serializable, ensure_ascii=False) + '\\n')\n",
    "\n",
    "# Đóng trình duyệt sau khi hoàn tất\n",
    "driver.quit()  # <======\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File đã được lưu với tên: D:\\\\BeatVn\\\\Data\\\\Data_10-25-2024\\\\post_tiktok_10-25-2024.xlsx'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_posts = convert_to_dataframe_data_video_txt(\"data_video.txt\")\n",
    "# save_file(data_posts, \"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'File đã được lưu với tên: D:\\\\BeatVn\\\\Data\\\\Data_10-23-2024\\\\page_tiktok_10-23-2024.xlsx'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_page = read_file(\"user_data.txt\")\n",
    "# data_page = convert_to_dataframe_from_txt(data_page)\n",
    "# save_file(data_page, \"Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myven",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
